{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Persiapan Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T09:05:57.219242Z",
     "iopub.status.busy": "2025-06-13T09:05:57.218883Z",
     "iopub.status.idle": "2025-06-13T09:05:57.671366Z",
     "shell.execute_reply": "2025-06-13T09:05:57.670501Z",
     "shell.execute_reply.started": "2025-06-13T09:05:57.219210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Memuat dataset CSV\n",
    "dataTest = pd.read_csv('input/emotion-dataset/test.csv')\n",
    "dataTraining = pd.read_csv('input/emotion-dataset/training.csv')\n",
    "dataValidation = pd.read_csv('input/emotion-dataset/validation.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T09:05:57.673324Z",
     "iopub.status.busy": "2025-06-13T09:05:57.673003Z",
     "iopub.status.idle": "2025-06-13T09:05:57.715252Z",
     "shell.execute_reply": "2025-06-13T09:05:57.714303Z",
     "shell.execute_reply.started": "2025-06-13T09:05:57.673296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Menghapus baris yang memiliki nilai kosong\n",
    "dataTest = dataTest.dropna()\n",
    "dataTraining = dataTraining.dropna()\n",
    "dataValidation = dataValidation.dropna()\n",
    "\n",
    "# Menghapus duplikat\n",
    "dataTest = dataTest.drop_duplicates()\n",
    "dataTraining = dataTraining.drop_duplicates()\n",
    "dataValidation = dataValidation.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 3 2 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Inisialisasi LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Mengubah label emosi menjadi angka\n",
    "y_train = label_encoder.fit_transform(dataTraining['label'])\n",
    "y_test = label_encoder.transform(dataTest['label'])\n",
    "y_val = label_encoder.transform(dataValidation['label'])\n",
    "\n",
    "# Menampilkan beberapa label yang sudah terencode\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T09:05:57.716536Z",
     "iopub.status.busy": "2025-06-13T09:05:57.716198Z",
     "iopub.status.idle": "2025-06-13T09:05:58.544562Z",
     "shell.execute_reply": "2025-06-13T09:05:58.543024Z",
     "shell.execute_reply.started": "2025-06-13T09:05:57.716507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encoding untuk label emosi\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-13T09:05:58.545337Z",
     "iopub.status.idle": "2025-06-13T09:05:58.545739Z",
     "shell.execute_reply": "2025-06-13T09:05:58.545574Z",
     "shell.execute_reply.started": "2025-06-13T09:05:58.545559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0                            i didnt feel humiliated   \n",
      "1  i can go from feeling so hopeless to so damned...   \n",
      "2   im grabbing a minute to post i feel greedy wrong   \n",
      "3  i am ever feeling nostalgic about the fireplac...   \n",
      "4                               i am feeling grouchy   \n",
      "\n",
      "                                  cleaned_text  \n",
      "0                           nt feel humiliated  \n",
      "1  feeling hopeless damned hopeful cares awake  \n",
      "2     m grabbing minute post feel greedy wrong  \n",
      "3    feeling nostalgic fireplace know property  \n",
      "4                              feeling grouchy  \n",
      "                                                text  \\\n",
      "0  im feeling rather rotten so im not very ambiti...   \n",
      "1          im updating my blog because i feel shitty   \n",
      "2  i never make her separate from me because i do...   \n",
      "3  i left with my bouquet of red and yellow tulip...   \n",
      "4    i was feeling a little vain when i did this one   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0                 m feeling rotten m ambitious right  \n",
      "1                        m updating blog feel shitty  \n",
      "2            separate don t want feel like m ashamed  \n",
      "3  left bouquet red yellow tulips arm feeling sli...  \n",
      "4                                feeling little vain  \n",
      "                                                text  \\\n",
      "0  im feeling quite sad and sorry for myself but ...   \n",
      "1  i feel like i am still looking at a blank canv...   \n",
      "2                     i feel like a faithful servant   \n",
      "3                  i am just feeling cranky and blue   \n",
      "4  i can have for a treat or if i am feeling festive   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0                  m feeling sad sorry ill snap soon  \n",
      "1  feel like looking blank canvas blank pieces paper  \n",
      "2                         feel like faithful servant  \n",
      "3                                feeling cranky blue  \n",
      "4                              treat feeling festive  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Memuat model bahasa Inggris spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def clean_text_spacy(text):\n",
    "    # Membuat objek doc dengan spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Menghapus stopwords, tanda baca, dan angka\n",
    "    cleaned_text = ' '.join([token.text for token in doc if not token.is_stop and not token.is_punct and not token.is_digit])\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Terapkan pembersihan pada kolom teks di dataset menggunakan spaCy\n",
    "dataTraining['cleaned_text'] = dataTraining['text'].apply(clean_text_spacy)\n",
    "dataTest['cleaned_text'] = dataTest['text'].apply(clean_text_spacy)\n",
    "dataValidation['cleaned_text'] = dataValidation['text'].apply(clean_text_spacy)\n",
    "\n",
    "# Menampilkan beberapa baris untuk memverifikasi\n",
    "print(dataTraining[['text', 'cleaned_text']].head())\n",
    "print(dataTest[['text', 'cleaned_text']].head())\n",
    "print(dataValidation[['text', 'cleaned_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15999, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Inisialisasi vektorisasi TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Membatasi jumlah fitur\n",
    "\n",
    "# Vektorisasi data pelatihan dan pengujian\n",
    "X_train_tfidf = vectorizer.fit_transform(dataTraining['cleaned_text'])\n",
    "X_test_tfidf = vectorizer.transform(dataTest['cleaned_text'])\n",
    "X_val_tfidf = vectorizer.transform(dataValidation['cleaned_text'])\n",
    "\n",
    "# Menampilkan bentuk data vektorisasi (misalnya jumlah fitur)\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       581\n",
      "           1       0.86      0.95      0.90       695\n",
      "           2       0.80      0.66      0.72       159\n",
      "           3       0.89      0.84      0.86       275\n",
      "           4       0.87      0.83      0.85       224\n",
      "           5       0.87      0.52      0.65        66\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.87      0.79      0.82      2000\n",
      "weighted avg       0.88      0.88      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Inisialisasi model Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Melatih model\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Prediksi pada data uji\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Akurasi: {accuracy:.2f}')\n",
    "\n",
    "# Menampilkan laporan klasifikasi\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       550\n",
      "           1       0.87      0.94      0.91       704\n",
      "           2       0.89      0.73      0.80       178\n",
      "           3       0.89      0.87      0.88       275\n",
      "           4       0.87      0.75      0.81       212\n",
      "           5       0.86      0.68      0.76        81\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.88      0.82      0.84      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi menggunakan data validasi\n",
    "y_val_pred = model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluasi dengan metrik yang lebih detail\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Menyimpan model dan vektorisasi\n",
    "joblib.dump(model, 'emotion_model.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n",
    "# Menyimpan LabelEncoder untuk label emosi\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1590810,
     "sourceId": 2617192,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
